{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PavelDaB/Deep-Learning-Exploration/blob/main/First%20Neural%20Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "#rerun all afterreload"
      ],
      "metadata": {
        "id": "vYgH2hnruF_h"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a model class inherits nn.Module\n",
        "class Model(nn.Module):\n",
        "  #Input layer 4 feats (s width, s length, p width, p length of iris flower) -> to a hidden layer (h1) -> h2 (n) -> output (3 classes: Setosa, Veriscolour, or Virginica)\n",
        "  def __init__(self, in_feature = 4, h1 = 8, h2 = 9, out_features = 3):\n",
        "    super().__init__() # makes the mod work\n",
        "    self.fc1 = nn.Linear(in_feature, h1)\n",
        "    self.fc2 = nn.Linear(h1, h2)\n",
        "    self.out = nn.Linear(h2, out_features)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.out(x)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "-3fe9kzlmdNA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Manual seed for rando\n",
        "torch.manual_seed(41)\n",
        "# Instance of mod\n",
        "model = Model()"
      ],
      "metadata": {
        "id": "w0Wd2cOapnOf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\"\n",
        "my_df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "tBo7f62yz7Zq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Went from strings to ints\n",
        "my_df['variety'] = my_df['variety'].replace('Setosa', 0.0)\n",
        "my_df['variety'] = my_df['variety'].replace('Versicolor', 1.0)\n",
        "my_df['variety'] = my_df['variety'].replace('Virginica', 2.0)"
      ],
      "metadata": {
        "id": "dc-tVmrl1iJ8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "X = my_df.drop('variety', axis = 1)\n",
        "y = my_df['variety']"
      ],
      "metadata": {
        "id": "_Ujri-_l-QRM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.values\n",
        "y = y.values"
      ],
      "metadata": {
        "id": "Yqk2iIvx-3V8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 41)"
      ],
      "metadata": {
        "id": "_Cd6GypY_MED"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.FloatTensor(X_train)\n",
        "X_test = torch.FloatTensor(X_test)"
      ],
      "metadata": {
        "id": "4vAlIA4I_iJE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = torch.LongTensor(y_train)\n",
        "y_test = torch.LongTensor(y_test)"
      ],
      "metadata": {
        "id": "kDi_z5KKABpU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# messures error\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# using adam optimizer, learn rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n"
      ],
      "metadata": {
        "id": "ew7qSj7Zb7CK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train, epochs\n",
        "epochs = 100\n",
        "losses = []\n",
        "for i in range(epochs): #go forward and get a pred\n",
        "  y_pred = model.forward(X_train)\n",
        "#measure loss/error\n",
        "  loss = criterion(y_pred, y_train)\n",
        "  losses.append(loss.detach().numpy()) # track of losses\n",
        "\n",
        "  if i % 10 == 0: #prints every 10\n",
        "    print(f'Epoch: {i} and loss: {loss}')\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n"
      ],
      "metadata": {
        "id": "uvDdEeWhlGua",
        "outputId": "8834e35a-655f-41c6-8850-7c5232d4739d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 and loss: 1.125203251838684\n",
            "Epoch: 10 and loss: 1.1095693111419678\n",
            "Epoch: 20 and loss: 1.0961166620254517\n",
            "Epoch: 30 and loss: 1.0845798254013062\n",
            "Epoch: 40 and loss: 1.0739582777023315\n",
            "Epoch: 50 and loss: 1.0637890100479126\n",
            "Epoch: 60 and loss: 1.0539253950119019\n",
            "Epoch: 70 and loss: 1.0440940856933594\n",
            "Epoch: 80 and loss: 1.0337880849838257\n",
            "Epoch: 90 and loss: 1.022811770439148\n"
          ]
        }
      ]
    }
  ]
}