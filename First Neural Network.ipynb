{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PavelDaB/Deep-Learning-Exploration/blob/main/First%20Neural%20Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "#rerun all afterreload"
      ],
      "metadata": {
        "id": "vYgH2hnruF_h"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a model class inherits nn.Module\n",
        "class Model(nn.Module):\n",
        "  #Input layer 4 feats (s width, s length, p width, p length of iris flower) -> to a hidden layer (h1) -> h2 (n) -> output (3 classes: Setosa, Veriscolour, or Virginica)\n",
        "  def __init__(self, in_feature = 4, h1 = 8, h2 = 9, out_features = 3):\n",
        "    super().__init__() # makes the mod work\n",
        "    self.fc1 = nn.Linear(in_feature, h1)\n",
        "    self.fc2 = nn.Linear(h1, h2)\n",
        "    self.out = nn.Linear(h2, out_features)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.out(x)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "-3fe9kzlmdNA"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Manual seed for rando\n",
        "torch.manual_seed(17)\n",
        "# Instance of mod\n",
        "model = Model()"
      ],
      "metadata": {
        "id": "w0Wd2cOapnOf"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\"\n",
        "my_df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "tBo7f62yz7Zq"
      },
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Went from strings to ints\n",
        "my_df['variety'] = my_df['variety'].replace('Setosa', 0)\n",
        "my_df['variety'] = my_df['variety'].replace('Versicolor', 1)\n",
        "my_df['variety'] = my_df['variety'].replace('Virginica', 2)"
      ],
      "metadata": {
        "id": "dc-tVmrl1iJ8"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "X = my_df.drop('variety', axis = 1)\n",
        "y = my_df['variety']"
      ],
      "metadata": {
        "id": "_Ujri-_l-QRM"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.values\n",
        "y = y.values"
      ],
      "metadata": {
        "id": "Yqk2iIvx-3V8"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 32)"
      ],
      "metadata": {
        "id": "_Cd6GypY_MED"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.FloatTensor(X_train)\n",
        "X_test = torch.FloatTensor(X_test)"
      ],
      "metadata": {
        "id": "4vAlIA4I_iJE"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = torch.LongTensor(y_train)\n",
        "y_test = torch.LongTensor(y_test)"
      ],
      "metadata": {
        "id": "kDi_z5KKABpU"
      },
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# messures error\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# using adam optimizer, learn rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n"
      ],
      "metadata": {
        "id": "ew7qSj7Zb7CK"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train, epochs\n",
        "epochs = 500\n",
        "losses = []\n",
        "for i in range(epochs): #go forward and get a pred\n",
        "  y_pred = model.forward(X_train)\n",
        "#measure loss/error\n",
        "  loss = criterion(y_pred, y_train)\n",
        "  losses.append(loss.detach().numpy()) # track of losses\n",
        "\n",
        "  if i % 10 == 0: #prints every 10\n",
        "    print(f'Epoch: {i} and loss: {loss}')\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n"
      ],
      "metadata": {
        "id": "uvDdEeWhlGua",
        "outputId": "599ae624-e74e-4c61-9c3c-e4af83893cfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 and loss: 1.1085662841796875\n",
            "Epoch: 10 and loss: 1.102394461631775\n",
            "Epoch: 20 and loss: 1.0389779806137085\n",
            "Epoch: 30 and loss: 0.9590866565704346\n",
            "Epoch: 40 and loss: 0.844763994216919\n",
            "Epoch: 50 and loss: 0.7159226536750793\n",
            "Epoch: 60 and loss: 0.6295926570892334\n",
            "Epoch: 70 and loss: 0.5507535934448242\n",
            "Epoch: 80 and loss: 0.4955293536186218\n",
            "Epoch: 90 and loss: 0.45244234800338745\n",
            "Epoch: 100 and loss: 0.4097839593887329\n",
            "Epoch: 110 and loss: 0.36203157901763916\n",
            "Epoch: 120 and loss: 0.3248656690120697\n",
            "Epoch: 130 and loss: 0.28978675603866577\n",
            "Epoch: 140 and loss: 0.2618557810783386\n",
            "Epoch: 150 and loss: 0.23659056425094604\n",
            "Epoch: 160 and loss: 0.20970256626605988\n",
            "Epoch: 170 and loss: 0.17858409881591797\n",
            "Epoch: 180 and loss: 0.16004212200641632\n",
            "Epoch: 190 and loss: 0.15239019691944122\n",
            "Epoch: 200 and loss: 0.14050666987895966\n",
            "Epoch: 210 and loss: 0.1205926164984703\n",
            "Epoch: 220 and loss: 0.11105918139219284\n",
            "Epoch: 230 and loss: 0.10912267118692398\n",
            "Epoch: 240 and loss: 0.09842489659786224\n",
            "Epoch: 250 and loss: 0.08882918208837509\n",
            "Epoch: 260 and loss: 0.088499054312706\n",
            "Epoch: 270 and loss: 0.0845516175031662\n",
            "Epoch: 280 and loss: 0.07734567672014236\n",
            "Epoch: 290 and loss: 0.07521964609622955\n",
            "Epoch: 300 and loss: 0.0744246244430542\n",
            "Epoch: 310 and loss: 0.07002189755439758\n",
            "Epoch: 320 and loss: 0.06652738153934479\n",
            "Epoch: 330 and loss: 0.06690505146980286\n",
            "Epoch: 340 and loss: 0.06561805307865143\n",
            "Epoch: 350 and loss: 0.06181004270911217\n",
            "Epoch: 360 and loss: 0.06118222326040268\n",
            "Epoch: 370 and loss: 0.06171558052301407\n",
            "Epoch: 380 and loss: 0.059181589633226395\n",
            "Epoch: 390 and loss: 0.0569782592356205\n",
            "Epoch: 400 and loss: 0.05704067647457123\n",
            "Epoch: 410 and loss: 0.05701146647334099\n",
            "Epoch: 420 and loss: 0.055662136524915695\n",
            "Epoch: 430 and loss: 0.05402698740363121\n",
            "Epoch: 440 and loss: 0.053804684430360794\n",
            "Epoch: 450 and loss: 0.0542580671608448\n",
            "Epoch: 460 and loss: 0.05377396568655968\n",
            "Epoch: 470 and loss: 0.05270516127347946\n",
            "Epoch: 480 and loss: 0.05170471966266632\n",
            "Epoch: 490 and loss: 0.0514516644179821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad(): #turns off back prop\n",
        "  y_eval = model.forward(X_test) #feats of test set, y eval will be predictions\n",
        "  loss = criterion(y_eval, y_test) # find loss of error\n"
      ],
      "metadata": {
        "id": "TyRgdtorcviH"
      },
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTN8DPcpdtE4",
        "outputId": "f2f67e77-22de-469a-d272-1393efaeda3c"
      },
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0296)"
            ]
          },
          "metadata": {},
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "with torch.no_grad():\n",
        "  for i, data in enumerate(X_test):\n",
        "    y_val = model.forward(data)\n",
        "\n",
        "    if y_test[i] == 0:\n",
        "      x = \"Setosa\"\n",
        "    elif y_test[i] == 1:\n",
        "      x = 'Versicolor'\n",
        "    else:\n",
        "      x = 'Virginica'\n",
        "\n",
        "\n",
        "    # Will tell us what type of flower class our network thinks it is\n",
        "    print(f'{i+1}.)  {str(y_val)} \\t {x} \\t {y_val.argmax().item()}')\n",
        "\n",
        "    # Correct or not\n",
        "    if y_val.argmax().item() == y_test[i]:\n",
        "      correct +=1\n",
        "\n",
        "print(f'We got {correct} correct!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEW8HaXsd7Sh",
        "outputId": "0a84550e-3963-4732-e071-6f90e38b2e94"
      },
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.)  tensor([-20.6772,   7.4745,   2.9384]) \t Versicolor \t 1\n",
            "2.)  tensor([ 11.2175,   5.3223, -11.9151]) \t Setosa \t 0\n",
            "3.)  tensor([ 11.2175,   5.3223, -11.9151]) \t Setosa \t 0\n",
            "4.)  tensor([-22.3837,   7.5709,   3.7529]) \t Versicolor \t 1\n",
            "5.)  tensor([-40.8760,   8.6160,  12.5794]) \t Virginica \t 2\n",
            "6.)  tensor([-45.9575,   8.9031,  15.0048]) \t Virginica \t 2\n",
            "7.)  tensor([ 11.2175,   5.3223, -11.9151]) \t Setosa \t 0\n",
            "8.)  tensor([ 11.2175,   5.3223, -11.9151]) \t Setosa \t 0\n",
            "9.)  tensor([-19.8237,   7.4262,   2.5311]) \t Versicolor \t 1\n",
            "10.)  tensor([ 11.2175,   5.3223, -11.9151]) \t Setosa \t 0\n",
            "11.)  tensor([-21.5279,   7.5226,   3.3445]) \t Versicolor \t 1\n",
            "12.)  tensor([-46.9788,   8.9609,  15.4923]) \t Virginica \t 2\n",
            "13.)  tensor([-8.4984,  6.7862, -2.8745]) \t Versicolor \t 1\n",
            "14.)  tensor([-8.1203,  6.7649, -3.0550]) \t Versicolor \t 1\n",
            "15.)  tensor([-40.3964,   8.5889,  12.3505]) \t Virginica \t 2\n",
            "16.)  tensor([-45.8644,   8.8979,  14.9603]) \t Virginica \t 2\n",
            "17.)  tensor([-23.5445,   7.6365,   4.3070]) \t Versicolor \t 1\n",
            "18.)  tensor([-34.9910,   8.2834,   9.7704]) \t Virginica \t 2\n",
            "19.)  tensor([-9.5900,  6.8479, -2.3535]) \t Versicolor \t 1\n",
            "20.)  tensor([ 11.2175,   5.3223, -11.9151]) \t Setosa \t 0\n",
            "21.)  tensor([ 11.2175,   5.3223, -11.9151]) \t Setosa \t 0\n",
            "22.)  tensor([-51.4176,   9.2117,  17.6109]) \t Virginica \t 2\n",
            "23.)  tensor([-32.4093,   8.1375,   8.5382]) \t Virginica \t 2\n",
            "24.)  tensor([ 11.2175,   5.3223, -11.9151]) \t Setosa \t 0\n",
            "25.)  tensor([ 11.2175,   5.3223, -11.9151]) \t Setosa \t 0\n",
            "26.)  tensor([-11.8286,   6.9744,  -1.2850]) \t Versicolor \t 1\n",
            "27.)  tensor([ 11.2175,   5.3223, -11.9151]) \t Setosa \t 0\n",
            "28.)  tensor([-53.2540,   9.3155,  18.4874]) \t Virginica \t 2\n",
            "29.)  tensor([ 11.2175,   5.3223, -11.9151]) \t Setosa \t 0\n",
            "30.)  tensor([ 11.2175,   5.3223, -11.9151]) \t Setosa \t 0\n",
            "We got 30 correct!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save\n",
        "torch.save(model.state_dict(), 'first_nerual_network')"
      ],
      "metadata": {
        "id": "vdNaWN8gqe-D"
      },
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = Model()\n",
        "new_model.load_state_dict(torch.load('first_nerual_network'))"
      ],
      "metadata": {
        "id": "vHfz5c35qmqN",
        "outputId": "66d69384-2b9d-4430-db73-d4c2bdacf1a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-250-d3847caf6a70>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  new_model.load_state_dict(torch.load('first_nerual_network'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.eval()"
      ],
      "metadata": {
        "id": "GYkfWErkrAlT",
        "outputId": "f1127d19-f6ab-412f-a2a7-94bab058f0ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (fc1): Linear(in_features=4, out_features=8, bias=True)\n",
              "  (fc2): Linear(in_features=8, out_features=9, bias=True)\n",
              "  (out): Linear(in_features=9, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 251
        }
      ]
    }
  ]
}